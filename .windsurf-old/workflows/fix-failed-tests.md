---
description: Corriger automatiquement les tests qui Ã©chouent avant de mettre Ã  jour les mÃ©triques
---

# /fix-failed-tests - Correction automatique des tests Ã©chouÃ©s

Ce workflow est dÃ©clenchÃ© automatiquement par `/release-metrics` lorsque des tests Ã©chouent.
Il analyse, corrige et valide chaque test jusqu'Ã  100% passing.

---

## ğŸ”„ Boucle de correction (max 10 itÃ©rations)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BOUCLE DE CORRECTION                         â”‚
â”‚                                                                 â”‚
â”‚  1. Parser test_results.txt â†’ Liste des tests FAILED            â”‚
â”‚                         â†“                                       â”‚
â”‚  2. Pour CHAQUE test Ã©chouÃ©:                                    â”‚
â”‚     a. Lire le message d'erreur                                 â”‚
â”‚     b. Localiser le fichier source                              â”‚
â”‚     c. Analyser la cause (assertion, panic, timeout)            â”‚
â”‚     d. Appliquer la correction                                  â”‚
â”‚                         â†“                                       â”‚
â”‚  3. Re-exÃ©cuter cargo test --workspace                          â”‚
â”‚                         â†“                                       â”‚
â”‚  4. Si FAILED > 0 â†’ Recommencer (max 10 itÃ©rations)             â”‚
â”‚     Si PASSED 100% â†’ Retourner Ã  /release-metrics               â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Ã‰tape 1: Parser les tests Ã©chouÃ©s

```powershell
# Extraire les noms des tests FAILED
$failedTests = Select-String -Path test_results.txt -Pattern "^test .* FAILED$" | ForEach-Object { $_.Line }
Write-Host "Tests Ã©chouÃ©s: $($failedTests.Count)"
$failedTests | ForEach-Object { Write-Host "  - $_" }
```

**Format attendu**:
```
test module::submodule::test_name ... FAILED
```

---

## Ã‰tape 2: Analyser chaque test Ã©chouÃ©

Pour CHAQUE test dans `$failedTests`:

### 2.1 Localiser le fichier source

```powershell
# Exemple: test velesql::parser::tests::test_parse_select
# â†’ Fichier: crates/velesdb-core/src/velesql/parser.rs ou parser/tests.rs
```

**RÃ¨gles de localisation**:
| Pattern | Fichier |
|---------|---------|
| `module::tests::test_xxx` | `src/module.rs` ou `src/module/mod.rs` |
| `module::submodule::tests::test_xxx` | `src/module/submodule.rs` |
| `tests::test_xxx` (integration) | `tests/*.rs` |

### 2.2 Lire le message d'erreur complet

Chercher dans `test_results.txt` le bloc entre:
```
---- module::test_name stdout ----
[message d'erreur]
```

### 2.3 Classifier le type d'Ã©chec

| Type | Pattern | Action |
|------|---------|--------|
| **Assertion failed** | `assertion failed` | Mettre Ã  jour la valeur attendue |
| **Panic** | `panicked at` | Corriger le code ou ajouter handling |
| **Timeout** | `test timed out` | Optimiser ou augmenter timeout |
| **Compile error** | `error[E` | Corriger l'erreur de compilation |
| **Expected vs Got** | `left: X, right: Y` | Ajuster assertion ou code |

---

## Ã‰tape 3: Appliquer les corrections

### 3.1 Cas: Assertion avec nouvelle valeur attendue

Si le test vÃ©rifie une mÃ©trique qui a changÃ© lÃ©gitimement:

```rust
// AVANT
assert_eq!(result.len(), 10);

// APRÃˆS (si la nouvelle valeur est correcte)
assert_eq!(result.len(), 12);
```

**âš ï¸ IMPORTANT**: Ne modifier l'assertion que si la NOUVELLE valeur est correcte.
Si le code est cassÃ©, corriger le CODE, pas le test.

### 3.2 Cas: Code cassÃ©

Si le test rÃ©vÃ¨le un vrai bug:

```
â†’ Lancer /debug-taskforce pour investiguer et corriger
```

### 3.3 Cas: Test obsolÃ¨te

Si le test teste une fonctionnalitÃ© supprimÃ©e ou modifiÃ©e:

```rust
// Option 1: Supprimer le test
#[test]
#[ignore = "Feature removed in v1.5.0"]
fn test_old_feature() { ... }

// Option 2: Adapter le test Ã  la nouvelle API
```

---

## Ã‰tape 4: Re-exÃ©cuter les tests

```powershell
# Re-exÃ©cuter uniquement les tests qui ont Ã©chouÃ© (plus rapide)
cargo test --workspace --release -- $failedTestNames 2>&1 | Tee-Object -FilePath test_rerun.txt

# VÃ©rifier le rÃ©sultat
$stillFailed = (Select-String -Path test_rerun.txt -Pattern "FAILED").Count
if ($stillFailed -eq 0) {
    Write-Host "âœ… Tous les tests corrigÃ©s!"
} else {
    Write-Host "âš ï¸ Encore $stillFailed tests Ã©chouÃ©s. ItÃ©ration suivante..."
}
```

---

## Ã‰tape 5: Validation finale

```powershell
# ExÃ©cuter TOUS les tests pour confirmer
cargo test --workspace --release 2>&1 | Tee-Object -FilePath test_final.txt

$totalPassed = (Select-String -Path test_final.txt -Pattern "test result: ok").Count
$totalFailed = (Select-String -Path test_final.txt -Pattern "FAILED").Count

if ($totalFailed -eq 0) {
    Write-Host "âœ… 100% tests passing - Retour Ã  /release-metrics"
} else {
    Write-Host "âŒ Ã‰chec aprÃ¨s 10 itÃ©rations - Investigation manuelle requise"
    Write-Host "Lancer: /debug-taskforce"
}
```

---

## ğŸ”€ DÃ©cision: Correction vs Investigation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ARBRE DE DÃ‰CISION                            â”‚
â”‚                                                                 â”‚
â”‚  Test Ã©chouÃ©                                                    â”‚
â”‚       â”‚                                                         â”‚
â”‚       â”œâ”€â”€ Assertion avec nouvelle valeur ?                      â”‚
â”‚       â”‚   â””â”€â”€ OUI â†’ Mettre Ã  jour l'assertion                   â”‚
â”‚       â”‚                                                         â”‚
â”‚       â”œâ”€â”€ Bug dans le code ?                                    â”‚
â”‚       â”‚   â””â”€â”€ OUI â†’ /debug-taskforce                            â”‚
â”‚       â”‚                                                         â”‚
â”‚       â”œâ”€â”€ Test obsolÃ¨te ?                                       â”‚
â”‚       â”‚   â””â”€â”€ OUI â†’ #[ignore] avec raison                       â”‚
â”‚       â”‚                                                         â”‚
â”‚       â””â”€â”€ IncomprÃ©hensible ?                                    â”‚
â”‚           â””â”€â”€ OUI â†’ /debug-taskforce                            â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ Checklist par test corrigÃ©

- [ ] Cause racine identifiÃ©e
- [ ] Correction appliquÃ©e (code OU assertion, pas les deux)
- [ ] Test passe en isolation (`cargo test test_name`)
- [ ] Pas de rÃ©gression sur autres tests
- [ ] Commentaire si changement non-trivial

---

## âš ï¸ RÃ¨gles strictes

1. **Ne JAMAIS supprimer un test** sans raison documentÃ©e
2. **Ne JAMAIS modifier une assertion** si le code est cassÃ©
3. **Maximum 10 itÃ©rations** avant escalade manuelle
4. **Chaque correction = 1 commit** pour traÃ§abilitÃ©
5. **Si doute â†’ /debug-taskforce** plutÃ´t que deviner

---

## ğŸ”— Workflows liÃ©s

| Situation | Workflow |
|-----------|----------|
| Bug complexe | `/debug-taskforce` |
| Refactoring nÃ©cessaire | `/refactor-module` |
| Retour aux mÃ©triques | `/release-metrics` |
| Commit des corrections | `/pre-commit` |

---

## Exemple complet

```
1. cargo test â†’ 3 FAILED
2. Parser: test_parse_select, test_hnsw_recall, test_simd_dot

3. test_parse_select:
   - Erreur: assertion failed: expected 5, got 6
   - Cause: Nouveau token ajoutÃ© dans parser
   - Action: assert_eq!(tokens.len(), 6)

4. test_hnsw_recall:
   - Erreur: recall 94.5% < 95% threshold
   - Cause: Changement d'algo HNSW
   - Action: â†’ /debug-taskforce (bug potentiel)

5. test_simd_dot:
   - Erreur: test timed out after 60s
   - Cause: Boucle infinie introduite
   - Action: â†’ /debug-taskforce

6. AprÃ¨s corrections: cargo test â†’ 100% PASSED
7. Retour Ã  /release-metrics
```

