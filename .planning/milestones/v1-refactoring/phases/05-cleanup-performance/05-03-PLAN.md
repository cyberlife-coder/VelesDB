---
phase: 5
plan: 3
name: SIMD Dispatch Optimization & Benchmarks
wave: 2
depends_on: ["05-01"]
autonomous: true
---

# Phase 5 Plan 3: SIMD Dispatch Optimization & Benchmarks

## Objective

Optimize SIMD dispatch to eliminate per-call branch overhead by caching function pointers in a `DistanceEngine` struct. Establish baseline benchmarks and verify no performance regression from Phase 3-4 refactoring.

## Context

**Requirements addressed:** PERF-01
**Phase goal contribution:** Reduces SIMD dispatch overhead from match-per-call to zero-cost function pointer indirection.

**Current dispatch state (from Phase 4 simd extraction):**
- `dispatch.rs` uses `OnceLock<SimdLevel>` for cached runtime detection
- Each call does: `match simd_level() { ... }` — single branch on cached enum
- Hot-path functions: `dot_product_native`, `squared_l2_native`, `cosine_similarity_native`
- Common embedding dims: 128, 384, 768, 1024, 1536

**Optimization opportunity:**
The current `match simd_level()` dispatch is fast (branch on cached enum) but generates multiple conditional branches per call. A `DistanceEngine` struct holding function pointers would reduce this to a single indirect call — eliminating branch misprediction on repeated calls (e.g., in HNSW search loops processing thousands of vectors).

**References:**
- arXiv:2505.07621 "Bang for the Buck" — function pointer dispatch for SIMD
- SimSIMD library uses similar function-pointer tables

## Tasks

### Task 1: Establish baseline benchmarks

**Files:** `crates/velesdb-core/benches/`

**Action:**
1. Identify existing SIMD benchmarks (benches/ directory)
2. Run baseline benchmarks for key dimensions: 128, 384, 768, 1536
3. Record results for: dot_product, squared_l2, cosine_similarity
4. Save baseline with `cargo bench -- --save-baseline before-dispatch-opt`

**Verify:**
```powershell
cargo bench -p velesdb-core --bench simd_benchmarks -- --save-baseline before
```

**Done when:**
- Baseline benchmark results saved
- Results documented in commit message

---

### Task 2: Implement DistanceEngine with cached function pointers

**Files:** `crates/velesdb-core/src/simd_native/dispatch.rs`

**Action:**
Create a `DistanceEngine` struct that caches function pointers at construction time:

```rust
/// Zero-overhead SIMD dispatch via cached function pointers.
///
/// Eliminates per-call match dispatch by resolving function pointers once
/// at construction. Use for hot loops (HNSW search, batch operations).
pub struct DistanceEngine {
    dot_product: fn(&[f32], &[f32]) -> f32,
    squared_l2: fn(&[f32], &[f32]) -> f32,
    cosine_similarity: fn(&[f32], &[f32]) -> f32,
}
```

Implementation:
1. Constructor resolves function pointers based on `simd_level()` and vector dimension
2. Each method is a thin `#[inline(always)]` wrapper around the function pointer
3. Provide a `Default` impl that uses the best available SIMD
4. Provide dimension-aware constructors for accumulator selection (1acc vs 2acc vs 4acc)
5. Keep existing `dot_product_native()` functions as-is (backward compatible)
6. Add `DistanceEngine` as an optional optimization for hot loops

Key design decisions:
- Use `fn` pointers (not `dyn Fn`) for zero-cost indirection
- The engine is `Send + Sync + Copy` for easy sharing across threads
- Unsafe function pointers wrapped in safe public API

**Verify:**
```powershell
cargo test -p velesdb-core --lib -- distance_engine
cargo clippy -p velesdb-core -- -D warnings
```

**Done when:**
- `DistanceEngine` compiles and passes clippy
- Unit tests verify correct dispatch for each SIMD level
- Existing tests still pass (backward compatible)

---

### Task 3: Benchmark and compare

**Files:** `crates/velesdb-core/benches/`

**Action:**
1. Add benchmark comparing `dot_product_native()` vs `DistanceEngine::dot_product()`
2. Run benchmarks for dimensions: 128, 384, 768, 1536
3. Compare with baseline: `cargo bench -- --baseline before`
4. Document results

Expected improvement:
- Small vectors (128d): Marginal (dispatch overhead is small relative to compute)
- Large vectors (1536d): Minimal (compute dominates)
- Batch operations: Measurable (amortized dispatch elimination over thousands of calls)

**Verify:**
```powershell
cargo bench -p velesdb-core --bench simd_benchmarks -- --baseline before
```

**Done when:**
- Benchmark comparison shows no regression
- Results documented
- DistanceEngine provides measurable improvement in batch scenarios

---

## Verification

After all tasks complete:

```powershell
cargo test -p velesdb-core --lib
cargo clippy --workspace -- -D warnings
cargo fmt --all --check
cargo bench -p velesdb-core --bench simd_benchmarks
```

## Success Criteria

- [ ] Baseline benchmarks established and saved
- [ ] `DistanceEngine` struct implemented with cached function pointers
- [ ] `DistanceEngine` is `Send + Sync + Copy`
- [ ] Existing `*_native()` functions unchanged (backward compatible)
- [ ] No performance regression vs. baseline
- [ ] Batch dispatch shows measurable improvement
- [ ] All quality gates pass
- [ ] All 2382+ tests pass

## Output

**Files created:**
- Benchmark additions to `crates/velesdb-core/benches/`

**Files modified:**
- `crates/velesdb-core/src/simd_native/dispatch.rs` — Add `DistanceEngine`
- `crates/velesdb-core/src/simd_native/mod.rs` — Re-export `DistanceEngine`
